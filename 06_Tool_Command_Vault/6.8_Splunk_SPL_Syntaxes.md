# Splunk SPL Syntax Cheat Sheet

> **Focus:** Data Manipulation (Piping, Aggregating, Cleaning, Formatting).
> **Core Concept:** The Pipe `|`. Everything to the left is filtering (Finding); everything to the right is processing (Analyzing).
> **Exam Strategy:** Copy the templates below and replace `<FIELD>` with `src_ip`, `user`, or `file_name`.

---

## Basic Logic & Filtering (The "WHERE")

*Use these to structure your initial search query.*

| Operator | Syntax Example | Note |
| :--- | :--- | :--- |
| **AND** | `index=main EventCode=4624` | Implicit (Space = AND). |
| **OR** | `(User="admin" OR User="root")` | **Must** use parentheses for OR logic! |
| **NOT** | `NOT User="SYSTEM"` | Case sensitive (must be uppercase). |
| **Wildcard** | `Image="*\\Temp\\*"` | Matches anything in between. |
| **Exists** | `CommandLine=*` | Returns events where field is not null. |
| **Missing** | `NOT CommandLine=*` | Returns events where field is null. |

---

## Statistics & Aggregation (The "STATS")
*How to turn 10,000 logs into 1 table. This is the most critical skill for BTL1.*

### Frequency Analysis (Stacking)

*Find the most common (or rarest) offenders.*

```spl
| stats count by <FIELD_NAME> 
| sort - count 
| head 20
```
- Use Case: "Which IP is scanning us the most?" / "Which User ran the most commands?"

### Rare Analysis (Anomalies)

*Find things that only happened once (often malicious).*

```spl
| stats count by <FIELD_NAME> 
| where count < 5
```
- Use Case: "Show me processes that only ran once on the entire network."

### Listing Values (Grouping)

*Group multiple events into one line to see scope.*

```spl
| stats count values(CommandLine) as Cmds, dc(ComputerName) as Unique_Hosts by User
```
- values(X): Lists all unique values of X for that User (deduplicated).
- list(X): Lists ALL values of X (including duplicates).
- dc(X): Distinct Count (e.g., "How many different computers did this user access?").

## Field Extraction & Cleaning

*When Splunk doesn't parse the field you need automatically.*

### Regex Extraction (Rex)

*Extract an IP, Email, or ID from the raw message (`_raw`).*

```spl
| rex field=_raw "From: (?<sender_email>[\w\.-]+@[\w\.-]+)"
| stats count by sender_email

| rex field=_raw "(?<extracted_ip>\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})"
| stats count by extracted_ip

| rex field=_raw "Hash: (?<file_hash>[A-Fa-f0-9]{32,64})"
| table _time, file_hash

| rex field=_raw "https?://(?<domain>[^/]+)"
| stats count by domain
```

*Extraction Strategy*
- Find the log: Look at the _raw text.
    - Example: Status=Blocked SrcIP=10.10.10.5 Action=Drop
- Identify the Anchor: What is directly to the left of your data?
    - Anchor: SrcIP=
- Construct Command:
    - | rex field=_raw "SrcIP=(?<my_ip>\S+)" (Translation: Find 'SrcIP=', capture non-space characters into 'my_ip')

### Rename Fields (Readability)

*Make the report look professional.*

```spl
| rename ComputerName as "Host System", Image as "Process Path"
```

### Create Conditional Fields (Eval)

*Tag events based on logic.*

```spl
| eval is_suspicious=if(count > 100, "YES", "NO")
```

## Time Analysis

*Timeline analysis for Incident Reports.*

### Time Chart (Visual Trends)

*Visualize spikes in traffic or failed logins.*

```spl
| timechart span=1h count by <FIELD_NAME>
```

### Time Bucketing (Text Timeline)

*Group events into time chunks (e.g., every 30 mins).*

```spl
| bin _time span=30m 
| stats count values(Image) by _time, ComputerName
```

### Statistical Outlier Detection (Z-Score)

*Advanced application of time bucketing to detect anomalies by comparing current activity against a rolling historical baseline.*

```spl
| bin _time span=<INTERVAL>
| stats count as <METRIC> by _time, <ENTITY>
| streamstats time_window=<WINDOW> avg(<METRIC>) as mu stdev(<METRIC>) as sigma by <ENTITY>
| eval z_score = (<METRIC> - mu) / sigma
| eval isOutlier = if(z_score > <THRESHOLD>, 1, 0)
| search isOutlier = 1
```
**Workflow Logic:**
* **Normalization:** bin aggregates data into fixed intervals (e.g., 1h, 15m).
* **Metric Definition:** stats defines the measurement (e.g., count, dc(dest_ip)).
* **Baselining:** streamstats calculates the Mean (mu) and Standard Deviation (sigma) over a sliding window (e.g., time_window=24h).
* **Deviation Scoring:** The Z-Score measures how many standard deviations the current value is from the mean.
    - <THRESHOLD> = 2: Standard sensitivity.
    - <THRESHOLD> = 3: High precision (statistically significant).

### Format Time (For Reporting)

*Convert Unix Epoch time to readable String.*

```spl
| eval Time=strftime(_time, "%Y-%m-%d %H:%M:%S")
| table Time, ComputerName, EventCode
```

## Advanced Association

*Find A, then use A to find B.*

### Standard Subsearch
```spl
index=main [ search index=main EventCode=4625 
| top limit=1 SourceNetworkAddress 
| rename SourceNetworkAddress as src_ip 
| fields src_ip ]
```
